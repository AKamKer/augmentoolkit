pipeline: classifier-creator-pipeline

api:
  large_model: meta-llama/Meta-Llama-3.1-70B-Instruct
  large_api_key: !!PLACEHOLDER!!
  large_base_url: https://api.deepinfra.com/v1/openai
  large_mode: api
  small_model: meta-llama/Meta-Llama-3.1-8B-Instruct
  small_base_url: https://api.deepinfra.com/v1/openai
  small_api_key: !!PLACEHOLDER!!
  small_mode: api
classification:
  classes: ['infantry', 'not infantry'] # !!ATTENTION!! change these in order to change what classes your classifier tries to predict
  desc: Classify whether the text is related to 0. "infantry" the infantry part of the Army or 1. "not infantry" army stuff in general. # !!ATTENTION!! this explanation will be used to create the classification rules. Tips: 1. make sure that your classes have self-descriptive names; 2. indicate the number and the name of the class together in this description (e.g., '0. "infantry"'); don't just name the classes again, use this space to explain them a bit.
  predict_on_whole_set_at_the_end: True
path:
  default_prompts: ./prompts_classifier
  input_dir: ./inputs/examples/facts
  output_dir: ./outputs/classifier_creator_test
  prompts: ./prompts_classifier
system:
  chunk_size: 900
  completion_mode: False
  concurrency_limit: 50
  required_accuracy: 0.9
  use_stop: True
training:
  max_iters: 5
  model_path: distilbert-base-uncased
  test_set_size: 10
  train_set_increment: 40
  train_set_size: 40
  truncation_type: head-tail # when head-tail, this takes the first and last characters. When anything else, slices the first characters.
meta_datagen:
  do_meta_datagen: False
  meta_datagen_keys: # note that we will likely NOT have the original question generation detail -- or maybe we do.... hmm how do we... how do we use the full output of that but with the repaired context? Simple we do not. Hmm. HMM. do both and just use a different prompt and out format for the repaired-from-the-start thing? Oh and that's another one the pipeline will want to be able to change the output format of each thing to arbitrary variations nad also add random rules to the thing like "all caps" and other random shit just to make it really good at instruction following. Thankfully we have the inputs and outputs so we can twist it nicely. The output format, maybe we want to include a regex or some code or some way of parsing it so that we can then convert it to something else. A thought for when I go all into the model making stage.
    - label_details
    - rules_creation_details
  meta_datagen_extras: